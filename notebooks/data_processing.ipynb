{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Data Processing\n",
    "\n",
    "#### Labels for categories:\n",
    "| Label & feature  | 1  | 2  | 3  | 4  | 5  | 6  | 7  |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "| P. Zone Class  | Cold  | Warm  | Hot  |   |   |   |  \n",
    "| P. Mass Class  | Jovian  | Neptunian | Superterran  | Terran  | Subterran  | Mercurian  |  \n",
    "|  P. Compostion Class | gas  | water-gas |  rocky-water  | rocky-iron  | iron  |   |   \n",
    "| P. Atmosphere Class  | hydrogen-rich  |  metals-rich | no-atmosphere  |   |   |   |   \n",
    "\n",
    "\n",
    "For P. Habitable Class, which is our target label, we have a 3 entry output [c1, c2, c3] corresponding to [non-h, meso-, psychro-] and do a softmax on it as our network output giving something like [0.95, 0.03, 0.02] which predicts non-habitable.\n",
    "\n",
    "Our target labels then need to be as follows (I think):\n",
    "\n",
    "non-habitable: [1, 0, 0]\n",
    "\n",
    "mesoplanet: [0, 1, 0]\n",
    "\n",
    "psychroplanet: [0, 0, 1]\n",
    "\n",
    "This would work with MSE loss because it only requires that prediction $x$ has the same shape as target $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries to re-label entries, assigning a numeric value to text label\n",
    "\n",
    "zone_class = {\"Cold\": 1, \"Warm\": 2, \"Hot\": 3}\n",
    "mass_class = {\"Jovian\": 1, \"Neptunian\": 2, \"Superterran\": 3, \"Terran\": 4, \"Subterran\": 5, \"Mercurian\": 6}\n",
    "composition_class = {\"gas\": 1, 'water-gas': 2, 'rocky-water': 3, 'rocky-iron': 4, 'iron': 5}\n",
    "atmosphere_class = {'hydrogen-rich': 1, 'metals-rich': 2, 'no-atmosphere': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "project_path = cwd.rsplit('\\\\', maxsplit=1)[0]\n",
    "case_num = 1\n",
    "df = pd.read_csv(os.path.join(project_path, f'data\\\\processed\\\\PHL-EC-Case{case_num}.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-label text-based values with corresponding number from above table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # re-label zone class\n",
    "# try: \n",
    "#     for label, val in zone_class.items():\n",
    "#         df.loc[df[\"P. Zone Class\"]==label, \"P. Zone Class\"] = val\n",
    "# except KeyError as exception:\n",
    "#     print(f'Excepted Key Error: {exception} - not included in this feature case')\n",
    "\n",
    "# # re-label mass class\n",
    "# try:\n",
    "#     for label, val in mass_class.items():\n",
    "#         df.loc[df[\"P. Mass Class\"]==label, \"P. Mass Class\"] = val\n",
    "# except KeyError as exception:\n",
    "#     print(f'Excepted Key Error: {exception} - not included in this feature case')\n",
    "\n",
    "# # re-label composition class\n",
    "# try:\n",
    "#     for label, val in composition_class.items():\n",
    "#         df.loc[df[\"P. Composition Class\"]==label, \"P. Composition Class\"] = val\n",
    "# except KeyError as exception:\n",
    "#     print(f'Excepted Key Error: {exception} - not included in this feature case')\n",
    "\n",
    "# # re-label atmosphere class\n",
    "# try:\n",
    "#     for label, val in atmosphere_class.items():\n",
    "#         df.loc[df[\"P. Atmosphere Class\"]==label, \"P. Atmosphere Class\"] = val\n",
    "# except KeyError as exception:\n",
    "#     print(f'Excepted Key Error: {exception} - not included in this feature case')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping \n",
    "\n",
    "The next step in data prcoessing is bootstrap aggregation, where we take the data set and produce equal number of samples from non-habitable, meso, and psychro type planets, so that the model is equally trained on all three types.\n",
    "\n",
    "We have 17 of hab_type 1 and 31 of hab_type 2, with excess of hab_type 0 (non-habitable). The paper mentions 40 times upsampling so we'll assume that means:\n",
    "$40 \\times 17 = 680$\n",
    "\n",
    "680 of each type giving us a total aggregrate dataset of 2040 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 12345 # seed to have consistent random samples\n",
    "num_samples = 680 # number of samples of each type of planet\n",
    "\n",
    "# split data into 3 dataframes based on habitability label\n",
    "df_0 = df[df[\"hab_lbl\"] == 0]\n",
    "df_1 = df[df[\"hab_lbl\"] == 1]\n",
    "df_2 = df[df[\"hab_lbl\"] == 2]\n",
    "\n",
    "# generate random indices for selectign samples\n",
    "np.random.seed(seed)\n",
    "rand_num_0 = np.random.randint(0, df_0.shape[0], size = num_samples)\n",
    "rand_num_1 = np.random.randint(0, df_1.shape[0], size = num_samples)\n",
    "rand_num_2 = np.random.randint(0, df_2.shape[0], size = num_samples)\n",
    "\n",
    "# convert to numpy arrays and sample\n",
    "agg_0 = df_0.to_numpy()[rand_num_0]\n",
    "agg_1 = df_1.to_numpy()[rand_num_1]\n",
    "agg_2 = df_2.to_numpy()[rand_num_2]\n",
    "\n",
    "# doing 80/20 train/test split we concatenate\n",
    "train = np.concatenate((agg_0[0:int(num_samples*0.8), :], agg_1[0:int(num_samples*0.8), :], agg_2[0:int(num_samples*0.8), :]))\n",
    "test = np.concatenate((agg_0[int(num_samples*0.8):, :], agg_1[int(num_samples*0.8):, :], agg_2[int(num_samples*0.8):, :]))\n",
    "\n",
    "# separating inputs and targets\n",
    "train_input, train_target1D = train[:, 1:], train[:, 0]\n",
    "test_input, test_target1D = test[:, 1:], test[:, 0]\n",
    "\n",
    "# turning targets from 1 -> [0, 1, 0], 2 -> [0, 0, 1], etc.\n",
    "train_target = np.empty((len(train_target1D), 3), dtype=int)\n",
    "train_target[np.where(train_target1D == 0), :] = [1, 0, 0]\n",
    "train_target[np.where(train_target1D == 1), :] = [0, 1, 0]\n",
    "train_target[np.where(train_target1D == 2), :] = [0, 0, 1]\n",
    "\n",
    "test_target = np.empty((len(test_target1D), 3), dtype=int)\n",
    "test_target[np.where(test_target1D == 0), :] = [1, 0, 0]\n",
    "test_target[np.where(test_target1D == 1), :] = [0, 1, 0]\n",
    "test_target[np.where(test_target1D == 2), :] = [0, 0, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 4, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1,2,3,4])\n",
    "arr2 = arr[[0, 0, 1, 2, 3, 2]]\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'case1'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = f'case{1}'\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c465ba086a0105c63437c5197f8f8ddd05147e62ac571a38827e30807fc41ec7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
